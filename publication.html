<html>

<head>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="stylesheet" type="text/css" href="style.css" />
    <title>Gang Niu (Senior Research Scientist at RIKEN)</title>
</head>

<body>
<h1 style="padding-left: 0.5em">Gang Niu (Senior Research Scientist at RIKEN)</h1><hr>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
    <div class="menu-item"><a href="index.html">Home</a></div>
    <div class="menu-item"><a href="publication.html" class="current">Publications</a></div>
    <div class="menu-item"><a href="talk.html">Invited Talks</a></div>
    <div class="menu-item"><a href="service.html">Professional Services</a></div>
    <div class="menu-item"><a href="https://wsl-workshop.github.io/software.html" target="_blank">Codes and Data</a></div>
    <div class="menu-item"><a href="misc.html">Miscellaneous</a></div>
</td>
<td id="layout-content">

    <h1 style="margin-top: 0em">Publications</h1><br>
    <p>[ <a href="#book">Books</a>,
         <a href="#preprint">Preprints</a>,
         <a href="#conference">Conference Papers</a>,
         <a href="#journal">Journal Articles</a>,
         <a href="#thesis">Theses</a> ]</p>
    <p>An asterisk (*) beside authors' names indicates equal contributions.</p>

    <div>
        <h2><hr><a name="book"></a>Books</h2>
        <ol>
            <li><p>
                M. Sugiyama, H. Bao, T. Ishida, N. Lu, T. Sakai, and G. Niu.<br>
                <i><a href="http://mitpress.mit.edu/books/machine-learning-weak-supervision" target="_blank">Machine Learning from Weak Supervision: An Empirical Risk Minimization Approach</a></i>,<br>
                320 pages, <i><a href="http://mitpress.mit.edu/books/series/adaptive-computation-and-machine-learning-series" target="_blank">Adaptive Computation and Machine Learning series</a></i>, The MIT Press, 2022.<br>
                <font color="#FF0000"><b>(My name is missing from the author list in all retailers due to a system issue of the distributor Penguin Random House;<br>
                Their information system can only store up to 5 authors who can be received by the retailers from their meta-data feeds)</b></font>
            </p></li>
            <li><p>
                K. Chaudhuri, S. Jegelka, L. Song, C. Szepesvari, G. Niu, S. Sabato (Eds.).<br>
                <i><a href="http://proceedings.mlr.press/v162/" target="_blank">Proceedings of 39th International Conference on Machine Learning (ICML 2022)</a></i>,<br>
                27723 pages, Proceedings of Machine Learning Research, vol. 162, 2022.
            </p></li>
        </ol>
    </div>

    <div>
        <h2><hr><a name="preprint"></a>Preprints (no review)</h2>
        <ol>
            <li><p>
                R. Gao, F. Liu, K. Zhou, G. Niu, B. Han, and J. Cheng.<br>
                Local reweighting for adversarial training.<br>
                [ <a href="http://arxiv.org/abs/2106.15776" target="_blank">arXiv</a> ]
            </p></li>
            <li><p>
                Y. Cao, L. Feng, S. Shu, Y. Xu, B. An, G. Niu, and M. Sugiyama.<br>
                Multi-class classification from single-class data with confidences.<br>
                [ <a href="http://arxiv.org/abs/2106.08864" target="_blank">arXiv</a> ]
            </p></li>
            <li><p>
                X. Xia, T. Liu, B. Han, M. Gong, J. Yu, G. Niu, and M. Sugiyama.<br>
                Instance correction for learning with open-set noisy labels.<br>
                [ <a href="http://arxiv.org/abs/2106.00455" target="_blank">arXiv</a> ]
            </p></li>
            <li><p>
                C. Chen*, J. Zhang*, X. Xu, T. Hu, G. Niu, G. Chen, and M. Sugiyama.<br>
                Guided interpolation for adversarial training.<br>
                [ <a href="http://arxiv.org/abs/2102.07327" target="_blank">arXiv</a> ]
            </p></li>
            <li><p>
                J. Zhu*, J. Zhang*, B. Han, T. Liu, G. Niu, H. Yang, M. Kankanhalli, and M. Sugiyama.<br>
                Understanding the interaction of adversarial training with noisy labels.<br>
                [ <a href="http://arxiv.org/abs/2102.03482" target="_blank">arXiv</a> ]
            </p></li>
            <li><p>
                S. Wu*, X. Xia*, T. Liu, B. Han, M. Gong, N. Wang, H. Liu, and G. Niu.<br>
                Multi-class classification from noisy-similarity-labeled data.<br>
                [ <a href="http://arxiv.org/abs/2002.06508" target="_blank">arXiv</a> ]
            </p></li>
            <li><p>
                J. Zhang*, B. Han*, G. Niu, T. Liu, and M. Sugiyama.<br>
                Where is the bottleneck of adversarial learning with unlabeled data?<br>
                [ <a href="http://arxiv.org/abs/1911.08696" target="_blank">arXiv</a> ]
            </p></li>
            <li><p>
                F. Liu, J. Lu, B. Han, G. Niu, G. Zhang, and M. Sugiyama.<br>
                Butterfly: A panacea for all difficulties in wildly unsupervised domain adaptation.<br>
                [ <a href="http://arxiv.org/abs/1905.07720" target="_blank">arXiv</a> ]
            </p></li>
            <li><p>
                C.-Y. Hsieh, M. Xu, G. Niu, H.-T. Lin, and M. Sugiyama.<br>
                A pseudo-label method for coarse-to-fine multi-label learning with limited supervision.<br>
                [ <a href="http://openreview.net/forum?id=rylVYjqHdN" target="_blank">OpenReview</a> ]
            </p></li>
            <li><p>
                M. Xu, B. Li, G. Niu, B. Han, and M. Sugiyama.<br>
                Revisiting sample selection approach to positive-unlabeled learning: Turning unlabeled data into positive rather than negative.<br>
                [ <a href="http://arxiv.org/abs/1901.10155" target="_blank">arXiv</a> ]
            </p></li>
            <li><p>
                M. Xu, G. Niu, B. Han, I. W. Tsang, Z.-H. Zhou, and M. Sugiyama.<br>
                Matrix co-completion for multi-label classification with missing features and labels.<br>
                [ <a href="http://arxiv.org/abs/1805.09156" target="_blank">arXiv</a> ]
            </p></li>
        </ol>
    </div>

    <div>
        <h2><hr><a name="conference"></a>Conference Papers (full review)</h2>
        <ol>
            <li><p>
                Z. Fan, S. Hu, J. Yao, G. Niu, Y. Zhang, M. Sugiyama, and Y. Wang.<br>
                Locally estimated global perturbations are better than local perturbations for federated sharpness-aware minimization.<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2024" target="_blank">41st International Conference on Machine Learning (ICML 2024)</a></i>,
                to appear.<br>
                [ paper ]
            </p></li>
            <li><p>
                W. Wang, T. Ishida, Y.-J. Zhang, G. Niu, and M. Sugiyama.<br>
                Learning with complementary labels revisited: The selected-completely-at-random setting is more practical.<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2024" target="_blank">41st International Conference on Machine Learning (ICML 2024)</a></i>,
                to appear.<br>
                [ paper ]
            </p></li>
            <li><p>
                K. Yan*, S. Cui*, A. Wuerkaixi, J. Zhang, B. Han, G. Niu, M. Sugiyama, and C. Zhang.<br>
                Balancing similarity and complementarity for federated learning.<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2024" target="_blank">41st International Conference on Machine Learning (ICML 2024)</a></i>,
                to appear.<br>
                [ paper ]
            </p></li>
            <li><p>
                M.-K. Xie*, J.-H. Xiao*, P. Peng, G. Niu, M. Sugiyama, and S.-J. Huang.<br>
                Counterfactual reasoning for multi-label image classification via patching-based training.<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2024" target="_blank">41st International Conference on Machine Learning (ICML 2024)</a></i>,
                to appear.<br>
                [ paper ]
            </p></li>
            <li><p>
                Z.-Y. Zhang, S. Han, H. Yao, G. Niu, and M. Sugiyama.<br>
                Generating chain-of-thoughts with a pairwise-comparison approach to searching for the most promising intermediate thought.<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2024" target="_blank">41st International Conference on Machine Learning (ICML 2024)</a></i>,
                to appear.<br>
                [ paper ]
            </p></li>
            <li><p>
                J. Xu, Y. Ren, X. Wang, L. Feng, Z. Zhang, G. Niu, and X. Zhu.<br>
                Investigating and mitigating the side effects of noisy views for self-supervised clustering algorithms in practical multi-view scenarios.<br>
                In <i>Proceedings of <a href="http://cvpr2024.thecvf.com/" target="_blank">2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2024)</a></i>,
                to appear.<br>
                [ paper ]
            </p></li>
            <li><p>
                A. Wuerkaixi, S. Cui, J. Zhang, K. Yan, B. Han, G. Niu, L. Fang, C. Zhang, and M. Sugiyama.<br>
                Accurate forgetting for heterogeneous federated continual learning.<br>
                In <i>Proceedings of <a href="http://iclr.cc/Conferences/2024/" target="_blank">12th International Conference on Learning Representations (ICLR 2024)</a></i>,
                19 pages, Vienna, Austria, May 7--11, 2024.<br>
                [ <a href="paper/wuerkaixi_iclr24.pdf" target="_blank">paper</a>,
                <a href="http://openreview.net/forum?id=ShQrnAsbPI" target="_blank">OpenReview</a> ]
            </p></li>
            <li><p>
                S. Chen, G. Niu, C. Gong, O. Koc, J. Yang, and M. Sugiyama.<br>
                Robust similarity learning with difference alignment regularization.<br>
                In <i>Proceedings of <a href="http://iclr.cc/Conferences/2024/" target="_blank">12th International Conference on Learning Representations (ICLR 2024)</a></i>,
                22 pages, Vienna, Austria, May 7--11, 2024.<br>
                [ <a href="paper/chen_iclr24.pdf" target="_blank">paper</a>,
                <a href="http://openreview.net/forum?id=K9V7ugVuUz" target="_blank">OpenReview</a> ]
            </p></li>
            <li><p>
                T. Fang, N. Lu, G. Niu, and M. Sugiyama.<br>
                Generalizing importance weighting to a universal solver for distribution shift problems.<br>
                In <i><a href="http://neurips.cc/Conferences/2023/" target="_blank">Advances in Neural Information Processing Systems 36 (NeurIPS 2023)</a></i>,
                pp. 24171--24190, New Orleans, Louisiana, USA, Dec 10--Dec 16, 2023.<br>
                <font color="#008800">(This paper was selected for spotlight presentation;
                spotlights : acceptance : submissions = 378 : 3218 : 12343)</font><br>
                [ <a href="paper/fang_neurips23.pdf" target="_blank">paper</a>,
                <a href="http://openreview.net/forum?id=KmdlUP23qh" target="_blank">OpenReview</a> ]
            </p></li>
            <li><p>
                J. Zhu, G. Yu, J. Yao, T. Liu, G. Niu, M. Sugiyama, and B. Han.<br>
                Diversified outlier exposure for out-of-distribution detection via informative extrapolation.<br>
                In <i><a href="http://neurips.cc/Conferences/2023/" target="_blank">Advances in Neural Information Processing Systems 36 (NeurIPS 2023)</a></i>,
                pp. 22702--22734, New Orleans, Louisiana, USA, Dec 10--Dec 16, 2023.<br>
                [ <a href="paper/zhu_neurips23.pdf" target="_blank">paper</a>,
                <a href="http://openreview.net/forum?id=RuxBLfiEqI" target="_blank">OpenReview</a> ]
            </p></li>
            <li><p>
                W. Wang, L. Feng, Y. Jiang, G. Niu, M.-L. Zhang, and M. Sugiyama.<br>
                Binary classification with confidence difference.<br>
                In <i><a href="http://neurips.cc/Conferences/2023/" target="_blank">Advances in Neural Information Processing Systems 36 (NeurIPS 2023)</a></i>,
                pp. 5936--5960, New Orleans, Louisiana, USA, Dec 10--Dec 16, 2023.<br>
                [ <a href="paper/wang_neurips23.pdf" target="_blank">paper</a>,
                <a href="http://openreview.net/forum?id=4RoD1o7yq6" target="_blank">OpenReview</a> ]
            </p></li>
            <li><p>
                J. Xu, S. Chen, Y. Ren, X. Shi, H.-T. Shen, G. Niu, and X. Zhu.<br>
                Self-weighted contrastive learning among multiple views for mitigating representation degeneration.<br>
                In <i><a href="http://neurips.cc/Conferences/2023/" target="_blank">Advances in Neural Information Processing Systems 36 (NeurIPS 2023)</a></i>,
                pp. 1119--1131, New Orleans, Louisiana, USA, Dec 10--Dec 16, 2023.<br>
                [ <a href="paper/xu_neurips23.pdf" target="_blank">paper</a>,
                <a href="http://openreview.net/forum?id=X8dbFcAox2" target="_blank">OpenReview</a> ]
            </p></li>
            <li><p>
                M.-K. Xie, J.-H. Xiao, H.-Z. Liu, G. Niu, M. Sugiyama, and S.-J. Huang.<br>
                Class-distribution-aware pseudo-labeling for semi-supervised multi-label learning.<br>
                In <i><a href="http://neurips.cc/Conferences/2023/" target="_blank">Advances in Neural Information Processing Systems 36 (NeurIPS 2023)</a></i>,
                pp. 25731--25747, New Orleans, Louisiana, USA, Dec 10--Dec 16, 2023.<br>
                [ <a href="paper/xie_neurips23.pdf" target="_blank">paper</a>,
                <a href="http://openreview.net/forum?id=UOB1UgPjuG" target="_blank">OpenReview</a> ]
            </p></li>
            <li><p>
                P. Yang, M.-K. Xie, C.-C. Zong, L. Feng, G. Niu, M. Sugiyama, and S.-J. Huang.<br>
                Multi-label knowledge distillation.<br>
                In <i>Proceedings of <a href="http://iccv2023.thecvf.com/" target="_blank">2023 IEEE/CVF International Conference on Computer Vision (ICCV 2023)</a></i>,
                pp. 17271--17280, Pairs, France, Oct 2--6, 2023.<br>
                [ <a href="paper/yang_iccv23.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                J. Tang, S. Chen, G. Niu, M. Sugiyama, and C. Gong.<br>
                Distribution shift matters for knowledge distillation with webly collected images.<br>
                In <i>Proceedings of <a href="http://iccv2023.thecvf.com/" target="_blank">2023 IEEE/CVF International Conference on Computer Vision (ICCV 2023)</a></i>,
                pp. 17470--17480, Pairs, France, Oct 2--6, 2023.<br>
                [ <a href="paper/tang_iccv23.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                R. Dong*, F. Liu*, H. Chi, T. Liu, M. Gong, G. Niu, M. Sugiyama, and B. Han.<br>
                Diversity-enhancing generative network for few-shot hypothesis adaptation.<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2023" target="_blank">40th International Conference on Machine Learning (ICML 2023)</a></i>,
                PMLR, vol. 202, pp. 8260--8275, Honolulu, Hawaii, USA, Jul 24--30, 2023.<br>
                [ <a href="paper/dong_icml23.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                H. Wei, H. Zhuang, R. Xie, L. Feng, G. Niu, B. An, and Y. Li.<br>
                Mitigating memorization of noisy labels by clipping the model prediction.<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2023" target="_blank">40th International Conference on Machine Learning (ICML 2023)</a></i>,
                PMLR, vol. 202, pp. 36868--36886, Honolulu, Hawaii, USA, Jul 24--30, 2023.<br>
                [ <a href="paper/hwei_icml23.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                Z. Wei, L. Feng, B. Han, T. Liu, G. Niu, X. Zhu, and H. Shen.<br>
                A universal unbiased method for classification from aggregate observations.<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2023" target="_blank">40th International Conference on Machine Learning (ICML 2023)</a></i>,
                PMLR, vol. 202, pp. 36804--36820, Honolulu, Hawaii, USA, Jul 24--30, 2023.<br>
                [ <a href="paper/zwei_icml23.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                S. Xia*, J. Lv*, N. Xu, G. Niu, and X. Geng.<br>
                Towards effective visual representations for partial-label learning.<br>
                In <i>Proceedings of <a href="http://cvpr2023.thecvf.com/" target="_blank">2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2023)</a></i>,
                pp. 15589--15598, Vancouver, British Columbia, Canada, Jun 18--22, 2023.<br>
                [ <a href="paper/xia_cvpr23.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                T. Ishida, I. Yamane, N. Charoenphakdee, G. Niu, and M. Sugiyama.<br>
                Is the performance of my deep network too good to be true? A direct approach to estimating the Bayes error in binary classification.<br>
                In <i>Proceedings of <a href="http://iclr.cc/Conferences/2023/" target="_blank">11th International Conference on Learning Representations (ICLR 2023)</a></i>,
                22 pages, Kigali, Rwanda, May 1--5, 2023.<br>
                <font color="#008800">(This paper was selected for oral presentation;
                orals : acceptance : submissions = 90 : 1579 : 4966)</font><br>
                [ <a href="paper/ishida_iclr23.pdf" target="_blank">paper</a>,
                <a href="http://openreview.net/forum?id=FZdJQgy05rz" target="_blank">OpenReview</a> ]
            </p></li>
            <li><p>
                J. Zhou*, J. Zhu*, J. Zhang, T. Liu, G. Niu, B. Han, and M. Sugiyama.<br>
                Adversarial training with complementary labels: On the benefit of gradually informative attacks.<br>
                In <i><a href="http://neurips.cc/Conferences/2022/" target="_blank">Advances in Neural Information Processing Systems 35 (NeurIPS 2022)</a></i>,
                pp. 23621--23633, New Orleans, Louisiana, USA, Nov 28--Dec 9, 2022.<br>
                [ <a href="paper/zhou_neurips22.pdf" target="_blank">paper</a>,
                <a href="http://openreview.net/forum?id=s7SukMH7ie9" target="_blank">OpenReview</a> ]
            </p></li>
            <li><p>
                S. Chen, C. Gong, J. Li, J. Yang, G. Niu, and M. Sugiyama.<br>
                Learning contrastive embedding in low-dimensional space.<br>
                In <i><a href="http://neurips.cc/Conferences/2022/" target="_blank">Advances in Neural Information Processing Systems 35 (NeurIPS 2022)</a></i>,
                pp. 6345--6357, New Orleans, Louisiana, USA, Nov 28--Dec 9, 2022.<br>
                [ <a href="paper/chen_neurips22.pdf" target="_blank">paper</a>,
                <a href="http://openreview.net/forum?id=stAKQ6vnFti" target="_blank">OpenReview</a> ]
            </p></li>
            <li><p>
                Y. Cao, T. Cai, L. Feng, L. Gu, J. Gu, B. An, G. Niu, and M. Sugiyama.<br>
                Generalizing consistent multi-class classification with rejection to be compatible with arbitrary losses.<br>
                In <i><a href="http://neurips.cc/Conferences/2022/" target="_blank">Advances in Neural Information Processing Systems 35 (NeurIPS 2022)</a></i>,
                pp. 521--534, New Orleans, Louisiana, USA, Nov 28--Dec 9, 2022.<br>
                [ <a href="paper/cao_neurips22.pdf" target="_blank">paper</a>,
                <a href="http://openreview.net/forum?id=DwHIcEyias" target="_blank">OpenReview</a> ]
            </p></li>
            <li><p>
                S. Yang, E. Yang, B. Han, Y. Liu, M. Xu, G. Niu, and T. Liu.<br>
                Estimating instance-dependent Bayes-label transition matrix using a deep neural network.<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2022" target="_blank">39th International Conference on Machine Learning (ICML 2022)</a></i>,
                PMLR, vol. 162, pp. 25302--25312, Baltimore, Maryland, USA, Jul 17--23, 2022.<br>
                [ <a href="paper/yang_icml22.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                J. Wei, H. Liu, T. Liu, G. Niu, M. Sugiyama, and Y. Liu.<br>
                To smooth or not? When label smoothing meets noisy labels.<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2022" target="_blank">39th International Conference on Machine Learning (ICML 2022)</a></i>,
                PMLR, vol. 162, pp. 23589--23614, Baltimore, Maryland, USA, Jul 17--23, 2022.<br>
                [ <a href="paper/wei_icml22.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                R. Gao, J. Wang, K. Zhou, F. Liu, B. Xie, G. Niu, B. Han, and J. Cheng.<br>
                Fast and reliable evaluation of adversarial robustness with minimum-margin attack.<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2022" target="_blank">39th International Conference on Machine Learning (ICML 2022)</a></i>,
                PMLR, vol. 162, pp. 7144--7163, Baltimore, Maryland, USA, Jul 17--23, 2022.<br>
                [ <a href="paper/gao_icml22.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                D. Cheng, T. Liu, Y. Ning, N. Wang, B. Han, G. Niu, X. Gao, and M. Sugiyama.<br>
                Instance-dependent label-noise learning with manifold-regularized transition matrix estimation.<br>
                In <i>Proceedings of <a href="http://cvpr2022.thecvf.com/" target="_blank">2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2022)</a></i>,
                pp. 16630--16639, New Orleans, Louisiana, USA, Jun 19--24, 2022.<br>
                [ <a href="paper/cheng_cvpr22.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                H. Wang, R. Xiao, Y. Li, L. Feng, G. Niu, G. Chen, and J. Zhao.<br>
                PiCO: Contrastive label disambiguation for partial label learning.<br>
                In <i>Proceedings of <a href="http://iclr.cc/Conferences/2022/" target="_blank">10th International Conference on Learning Representations (ICLR 2022)</a></i>,
                18 pages, Online, Apr 25--29, 2022.<br>
                <font color="#008800">(This paper was selected for oral presentation;
                orals : acceptance : submissions = 55 : 1094 : 3391)</font><br>
                <font color="#008800">(In addition, this paper received Outstanding Paper Honorable Mention)</font><br>
                [ <a href="paper/wang_iclr22.pdf" target="_blank">paper</a>,
                <a href="http://openreview.net/forum?id=EhYjZy6e1gJ" target="_blank">OpenReview</a> ]
            </p></li>
            <li><p>
                H. Chi*, F. Liu*, W. Yang, L. Lan, T. Liu, B. Han, G. Niu, M. Zhou, and M. Sugiyama.<br>
                Meta discovery: Learning to discover novel classes given very limited data.<br>
                In <i>Proceedings of <a href="http://iclr.cc/Conferences/2022/" target="_blank">10th International Conference on Learning Representations (ICLR 2022)</a></i>,
                20 pages, Online, Apr 25--29, 2022.<br>
                <font color="#008800">(This paper was selected for spotlight presentation;
                spotlights : acceptance : submissions = 176 : 1094 : 3391)</font><br>
                [ <a href="paper/chi_iclr22.pdf" target="_blank">paper</a>,
                <a href="http://openreview.net/forum?id=MEpKGLsY8f" target="_blank">OpenReview</a> ]
            </p></li>
            <li><p>
                Y. Yao, T. Liu, B. Han, M. Gong, G. Niu, M. Sugiyama, and D. Tao.<br>
                Rethinking class-prior estimation for positive-unlabeled learning.<br>
                In <i>Proceedings of <a href="http://iclr.cc/Conferences/2022/" target="_blank">10th International Conference on Learning Representations (ICLR 2022)</a></i>,
                21 pages, Online, Apr 25--29, 2022.<br>
                [ <a href="paper/yao_iclr22.pdf" target="_blank">paper</a>,
                <a href="http://openreview.net/forum?id=aYAA-XHKyk" target="_blank">OpenReview</a> ]
            </p></li>
            <li><p>
                J. Wei, Z. Zhu, H. Cheng, T. Liu, G. Niu, and Y. Liu.<br>
                Learning with noisy labels revisited: A study using real-world human annotations.<br>
                In <i>Proceedings of <a href="http://iclr.cc/Conferences/2022/" target="_blank">10th International Conference on Learning Representations (ICLR 2022)</a></i>,
                23 pages, Online, Apr 25--29, 2022.<br>
                [ <a href="http://noisylabels.com/" target="_blank"> CIFAR-N Dataset</a>,
                <a href="paper/wei_iclr22.pdf" target="_blank">paper</a>,
                <a href="http://openreview.net/forum?id=TBWA6PLJZQm" target="_blank">OpenReview</a> ]
            </p></li>
            <li><p>
                F. Zhang, L. Feng, B. Han, T. Liu, G. Niu, T. Qin, and M. Sugiyama.<br>
                Exploiting class activation value for partial-label learning.<br>
                In <i>Proceedings of <a href="http://iclr.cc/Conferences/2022/" target="_blank">10th International Conference on Learning Representations (ICLR 2022)</a></i>,
                17 pages, Online, Apr 25--29, 2022.<br>
                [ <a href="paper/fzhang_iclr22.pdf" target="_blank">paper</a>,
                <a href="http://openreview.net/forum?id=qqdXHUGec9h" target="_blank">OpenReview</a> ]
            </p></li>
            <li><p>
                J. Zhu, J. Yao, B. Han, J. Zhang, T. Liu, G. Niu, J. Zhou, J. Xu, and H. Yang.<br>
                Reliable adversarial distillation with unreliable teachers.<br>
                In <i>Proceedings of <a href="http://iclr.cc/Conferences/2022/" target="_blank">10th International Conference on Learning Representations (ICLR 2022)</a></i>,
                15 pages, Online, Apr 25--29, 2022.<br>
                [ <a href="paper/zhu_iclr22.pdf" target="_blank">paper</a>,
                <a href="http://openreview.net/forum?id=u6TRGdzhfip" target="_blank">OpenReview</a> ]
            </p></li>
            <li><p>
                N. Lu, Z. Wang, X. Li, G. Niu, Q. Dou, and M. Sugiyama.<br>
                Federated learning from only unlabeled data with class-conditional-sharing clients.<br>
                In <i>Proceedings of <a href="http://iclr.cc/Conferences/2022/" target="_blank">10th International Conference on Learning Representations (ICLR 2022)</a></i>,
                22 pages, Online, Apr 25--29, 2022.<br>
                [ <a href="paper/lu_iclr22.pdf" target="_blank">paper</a>,
                <a href="http://openreview.net/forum?id=WHA8009laxu" target="_blank">OpenReview</a> ]
            </p></li>
            <li><p>
                Y. Zhang, M. Gong, T. Liu, G. Niu, X. Tian, B. Han, B. Schölkopf, and K. Zhang.<br>
                CausalAdv: Adversarial robustness through the lens of causality.<br>
                In <i>Proceedings of <a href="http://iclr.cc/Conferences/2022/" target="_blank">10th International Conference on Learning Representations (ICLR 2022)</a></i>,
                20 pages, Online, Apr 25--29, 2022.<br>
                [ <a href="paper/yzhang_iclr22.pdf" target="_blank">paper</a>,
                <a href="http://openreview.net/forum?id=cZAi1yWpiXQ" target="_blank">OpenReview</a> ]
            </p></li>
            <li><p>
                X. Xia, T. Liu, B. Han, M. Gong, J. Yu, G. Niu, and M. Sugiyama.<br>
                Sample selection with uncertainty of losses for learning with noisy labels.<br>
                In <i>Proceedings of <a href="http://iclr.cc/Conferences/2022/" target="_blank">10th International Conference on Learning Representations (ICLR 2022)</a></i>,
                23 pages, Online, Apr 25--29, 2022.<br>
                [ <a href="paper/xia_iclr22.pdf" target="_blank">paper</a>,
                <a href="http://openreview.net/forum?id=xENf4QUL4LW" target="_blank">OpenReview</a> ]
            </p></li>
            <li><p>
                Y. Bai*, E. Yang*, B. Han, Y. Yang, J. Li, Y. Mao, G. Niu, and T. Liu.<br>
                Understanding and improving early stopping for learning with noisy labels.<br>
                In <i><a href="http://neurips.cc/Conferences/2021/" target="_blank">Advances in Neural Information Processing Systems 34 (NeurIPS 2021)</a></i>,
                pp. 24392--24403, Online, Dec 6--14, 2021.<br>
                [ <a href="paper/bai_neurips21.pdf" target="_blank">paper</a>,
                <a href="http://openreview.net/forum?id=KbV-UZRKb3g" target="_blank">OpenReview</a> ]
            </p></li>
            <li><p>
                Q. Wang*, F. Liu*, B. Han, T. Liu, C. Gong, G. Niu, M. Zhou, and M. Sugiyama.<br>
                Probabilistic margins for instance reweighting in adversarial training.<br>
                In <i><a href="http://neurips.cc/Conferences/2021/" target="_blank">Advances in Neural Information Processing Systems 34 (NeurIPS 2021)</a></i>,
                pp. 23258--23269, Online, Dec 6--14, 2021.<br>
                [ <a href="paper/wang_neurips21.pdf" target="_blank">paper</a>,
                <a href="http://openreview.net/forum?id=rg8gNkvs3u" target="_blank">OpenReview</a> ]
            </p></li>
            <li><p>
                Y. Yao, T. Liu, M. Gong, B. Han, G. Niu, and K. Zhang.<br>
                Instance-dependent label-noise learning under a structural causal model.<br>
                In <i><a href="http://neurips.cc/Conferences/2021/" target="_blank">Advances in Neural Information Processing Systems 34 (NeurIPS 2021)</a></i>,
                pp. 4409--4420, Online, Dec 6--14, 2021.<br>
                [ <a href="paper/yao_neurips21.pdf" target="_blank">paper</a>,
                <a href="http://openreview.net/forum?id=d20KTY2VrNk" target="_blank">OpenReview</a> ]
            </p></li>
            <li><p>
                L. Feng, S. Shu, Y. Cao, L. Tao, H. Wei, T. Xiang, B. An, and G. Niu.<br>
                Multiple-instance learning from similar and dissimilar bags.<br>
                In <i>Proceedings of <a href="http://www.kdd.org/kdd2021/" target="_blank">27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD 2021)</a></i>,
                pp. 374--382, Online, Aug 14--18, 2021.<br>
                [ <a href="paper/feng_kdd21.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                S. Chen, G. Niu, C. Gong, J. Li, J. Yang, and M. Sugiyama.<br>
                Large-margin contrastive learning with distance polarization regularizer.<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2021" target="_blank">38th International Conference on Machine Learning (ICML 2021)</a></i>,
                PMLR, vol. 139, pp. 1673--1683, Online, Jul 18--24, 2021.<br>
                [ <a href="paper/chen_icml21.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                H. Yan, J. Zhang, G. Niu, J. Feng, V. Y. F. Tan, and M. Sugiyama.<br>
                CIFS: Improving adversarial robustness of CNNs via channel-wise importance-based feature selection.<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2021" target="_blank">38th International Conference on Machine Learning (ICML 2021)</a></i>,
                PMLR, vol. 139, pp. 11693--11703, Online, Jul 18--24, 2021.<br>
                [ <a href="paper/yan_icml21.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                R. Gao*, F. Liu*, J. Zhang*, B. Han, T. Liu, G. Niu, and M. Sugiyama.<br>
                Maximum mean discrepancy test is aware of adversarial attacks.<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2021" target="_blank">38th International Conference on Machine Learning (ICML 2021)</a></i>,
                PMLR, vol. 139, pp. 3564--3575, Online, Jul 18--24, 2021.<br>
                [ <a href="paper/gao_icml21.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                X. Li, T. Liu, B. Han, G. Niu, and M. Sugiyama.<br>
                Provably end-to-end label-noise learning without anchor points.<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2021" target="_blank">38th International Conference on Machine Learning (ICML 2021)</a></i>,
                PMLR, vol. 139, pp. 6403--6413, Online, Jul 18--24, 2021.<br>
                [ <a href="paper/li_icml21.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                X. Du*, J. Zhang*, B. Han, T. Liu, Y. Rong, G. Niu, J. Huang, and M. Sugiyama.<br>
                Learning diverse-structured networks for adversarial robustness.<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2021" target="_blank">38th International Conference on Machine Learning (ICML 2021)</a></i>,
                PMLR, vol. 139, pp. 2880--2891, Online, Jul 18--24, 2021.<br>
                [ <a href="paper/du_icml21.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                A. Berthon, B. Han, G. Niu, T. Liu, and M. Sugiyama.<br>
                Confidence scores make instance-dependent label-noise learning possible.<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2021" target="_blank">38th International Conference on Machine Learning (ICML 2021)</a></i>,
                PMLR, vol. 139, pp. 825--836, Online, Jul 18--24, 2021.<br>
                [ <a href="paper/berthon_icml21.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                Y. Zhang, G. Niu, and M. Sugiyama.<br>
                Learning noise transition matrix from only noisy labels via total variation regularization.<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2021" target="_blank">38th International Conference on Machine Learning (ICML 2021)</a></i>,
                PMLR, vol. 139, pp. 12501--12512, Online, Jul 18--24, 2021.<br>
                [ <a href="paper/zhang_icml21.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                L. Feng, S. Shu, N. Lu, B. Han, M. Xu, G. Niu, B. An, and M. Sugiyama.<br>
                Pointwise binary classification with pairwise confidence comparisons.<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2021" target="_blank">38th International Conference on Machine Learning (ICML 2021)</a></i>,
                PMLR, vol. 139, pp. 3252--3262, Online, Jul 18--24, 2021.<br>
                [ <a href="paper/feng_icml21.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                N. Lu*, S. Lei*, G. Niu, I. Sato, and M. Sugiyama.<br>
                Binary classification from multiple unlabeled datasets via surrogate set classification.<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2021" target="_blank">38th International Conference on Machine Learning (ICML 2021)</a></i>,
                PMLR, vol. 139, pp. 7134--7144, Online, Jul 18--24, 2021.<br>
                [ <a href="paper/lu_icml21.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                Y. Cao, L. Feng, Y. Xu, B. An, G. Niu, and M. Sugiyama.<br>
                Learning from similarity-confidence data.<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2021" target="_blank">38th International Conference on Machine Learning (ICML 2021)</a></i>,
                PMLR, vol. 139, pp. 1272--1282, Online, Jul 18--24, 2021.<br>
                [ <a href="paper/cao_icml21.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                S. Wu*, X. Xia*, T. Liu, B. Han, M. Gong, N. Wang, H. Liu, and G. Niu.<br>
                Class2Simi: A noise reduction perspective on learning with noisy labels.<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2021" target="_blank">38th International Conference on Machine Learning (ICML 2021)</a></i>,
                PMLR, vol. 139, pp. 11285--11295, Online, Jul 18--24, 2021.<br>
                [ <a href="paper/wu_icml21.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                J. Zhang, J. Zhu, G. Niu, B. Han, M. Sugiyama, and M. Kankanhalli.<br>
                Geometry-aware instance-reweighted adversarial training.<br>
                In <i>Proceedings of <a href="http://iclr.cc/Conferences/2021/" target="_blank">9th International Conference on Learning Representations (ICLR 2021)</a></i>,
                29 pages, Online, May 3--7, 2021.<br>
                <font color="#008800">(This paper was selected for oral presentation;
                orals : acceptance : submissions = 53 : 860 : 2997)</font><br>
                [ <a href="paper/zhang_iclr21.pdf" target="_blank">paper</a>,
                <a href="http://openreview.net/forum?id=iAX0l6Cz8ub" target="_blank">OpenReview</a> ]
            </p></li>
            <li><p>
                A. Jacovi, G. Niu, Y. Goldberg, and M. Sugiyama.<br>
                Scalable evaluation and improvement of document set expansion via neural positive-unlabeled learning.<br>
                In <i>Proceedings of <a href="http://2021.eacl.org/" target="_blank">16th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2021)</a></i>,
                pp. 581--592, Online, Apr 19--23, 2021.<br>
                [ <a href="paper/jacovi_eacl21.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                Q. Wang, B. Han, T. Liu, G. Niu, J. Yang, and C. Gong.<br>
                Tackling instance-dependent label noise via a universal probabilistic model.<br>
                In <i>Proceedings of <a href="http://aaai.org/Conferences/AAAI-21/" target="_blank">35th AAAI Conference on Artificial Intelligence (AAAI 2021)</a></i>,
                pp. 10183--10191, Online, Feb 2--9, 2021.<br>
                [ <a href="paper/wang_aaai21.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                X. Xia, T. Liu, B. Han, N. Wang, M. Gong, H. Liu, G. Niu, D. Tao, and M. Sugiyama.<br>
                Part-dependent label noise: Towards instance-dependent label noise.<br>
                In <i><a href="http://neurips.cc/Conferences/2020/" target="_blank">Advances in Neural Information Processing Systems 33 (NeurIPS 2020)</a></i>,
                pp. 7597--7610, Online, Dec 6--12, 2020.<br>
                <font color="#008800">(This paper was selected for spotlight presentation;
                spotlights : acceptance : submissions = 280 : 1900 : 9454)</font><br>
                [ <a href="paper/xia_neurips20.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                T. Fang*, N. Lu*, G. Niu, and M. Sugiyama.<br>
                Rethinking importance weighting for deep learning under distribution shift.<br>
                In <i><a href="http://neurips.cc/Conferences/2020/" target="_blank">Advances in Neural Information Processing Systems 33 (NeurIPS 2020)</a></i>,
                pp. 11996--12007, Online, Dec 6--12, 2020.<br>
                <font color="#008800">(This paper was selected for spotlight presentation;
                spotlights : acceptance : submissions = 280 : 1900 : 9454)</font><br>
                [ <a href="paper/fang_neurips20.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                Y. Yao, T. Liu, B. Han, M. Gong, J. Deng, G. Niu, and M. Sugiyama.<br>
                Dual T: Reducing estimation error for transition matrix in label-noise learning.<br>
                In <i><a href="http://neurips.cc/Conferences/2020/" target="_blank">Advances in Neural Information Processing Systems 33 (NeurIPS 2020)</a></i>,
                pp. 7260--7271, Online, Dec 6--12, 2020.<br>
                [ <a href="paper/yao_neurips20.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                L. Feng, J. Lv, B. Han, M. Xu, G. Niu, X. Geng, B. An, and M. Sugiyama.<br>
                Provably consistent partial-label learning.<br>
                In <i><a href="http://neurips.cc/Conferences/2020/" target="_blank">Advances in Neural Information Processing Systems 33 (NeurIPS 2020)</a></i>,
                pp. 10948--10960, Online, Dec 6--12, 2020.<br>
                [ <a href="paper/feng_neurips20.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                C. Wang, B. Han, S. Pan, J. Jiang, G. Niu, and G. Long.<br>
                Cross-graph: Robust and unsupervised embedding for attributed graphs with corrupted structure.<br>
                In <i>Proceedings of <a href="http://icdm2020.bigke.org/" target="_blank">20th IEEE International Conference on Data Mining (ICDM 2020)</a></i>,
                pp. 571-580, Online, Nov 17--20, 2020.<br>
                [ <a href="paper/wang_icdm20.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                J. Zhang*, X. Xu*, B. Han, G. Niu, L. Cui, M. Sugiyama, and M. Kankanhalli.<br>
                Attacks which do not kill training make adversarial learning stronger.<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2020" target="_blank">37th International Conference on Machine Learning (ICML 2020)</a></i>,
                PMLR, vol. 119, pp. 11278--11287, Online, Jul 12--18, 2020.<br>
                [ <a href="paper/zhang_icml20.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                B. Han, G. Niu, X. Yu, Q. Yao, M. Xu, I. W. Tsang, and M. Sugiyama.<br>
                SIGUA: Forgetting may make learning with noisy labels more robust.<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2020" target="_blank">37th International Conference on Machine Learning (ICML 2020)</a></i>,
                PMLR, vol. 119, pp. 4006--4016, Online, Jul 12--18, 2020.<br>
                [ <a href="paper/han_icml20.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                L. Feng*, T. Kaneko*, B. Han, G. Niu, B. An, and M. Sugiyama.<br>
                Learning with multiple complementary labels.<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2020" target="_blank">37th International Conference on Machine Learning (ICML 2020)</a></i>,
                PMLR, vol. 119, pp. 3072--3081, Online, Jul 12--18, 2020.<br>
                [ <a href="paper/feng_icml20.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                Y.-T. Chou, G. Niu, H.-T. Lin, and M. Sugiyama.<br>
                Unbiased risk estimators can mislead: A case study of learning with complementary labels.<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2020" target="_blank">37th International Conference on Machine Learning (ICML 2020)</a></i>,
                PMLR, vol. 119, pp. 1929--1938, Online, Jul 12--18, 2020.<br>
                [ <a href="paper/chou_icml20.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                Q. Yao, H. Yang, B. Han, G. Niu, and J. T. Kwok.<br>
                Searching to exploit memorization effect in learning with noisy labels.<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2020" target="_blank">37th International Conference on Machine Learning (ICML 2020)</a></i>,
                PMLR, vol. 119, pp. 10789--10798, Online, Jul 12--18, 2020.<br>
                [ <a href="paper/yao_icml20.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                J. Lv, M. Xu, L. Feng, G. Niu, X. Geng, and M. Sugiyama.<br>
                Progressive identification of true labels for partial-label learning.<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2020" target="_blank">37th International Conference on Machine Learning (ICML 2020)</a></i>,
                PMLR, vol. 119, pp. 6500--6510, Online, Jul 12--18, 2020.<br>
                [ <a href="paper/lv_icml20.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                T. Ishida, I. Yamane, T. Sakai, G. Niu, and M. Sugiyama.<br>
                Do we need zero training loss after achieving zero training error?<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2020" target="_blank">37th International Conference on Machine Learning (ICML 2020)</a></i>,
                PMLR, vol. 119, pp. 4604--4614, Online, Jul 12--18, 2020.<br>
                [ <a href="paper/ishida_icml20.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                N. Lu, T. Zhang, G. Niu, and M. Sugiyama.<br>
                Mitigating overfitting in supervised classification from two unlabeled datasets: A consistent risk correction approach.<br>
                In <i>Proceedings of <a href="http://aistats.org/aistats2020/" target="_blank">23rd International Conference on Artificial Intelligence and Statistics (AISTATS 2020)</a></i>,
                PMLR, vol. 108, pp. 1115--1125, Online, Aug 26--28, 2020.<br>
                [ <a href="paper/lu_aistats20.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                C. Li, M. E. Khan, Z. Sun, G. Niu, B. Han, S. Xie, and Q. Zhao.<br>
                Beyond unfolding: Exact recovery of latent convex tensor decomposition under reshuffling.<br>
                In <i>Proceedings of <a href="http://aaai.org/Conferences/AAAI-20/" target="_blank">34th AAAI Conference on Artificial Intelligence (AAAI 2020)</a></i>,
                pp. 4602--4609, New York, New York, USA, Feb 7--12, 2020.<br>
                [ <a href="paper/li_aaai20.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                L. Xu, J. Honda, G. Niu, and M. Sugiyama.<br>
                Uncoupled regression from pairwise comparison data.<br>
                In <i><a href="http://neurips.cc/Conferences/2019/" target="_blank">Advances in Neural Information Processing Systems 32 (NeurIPS 2019)</a></i>,
                pp. 3992--4002, Vancouver, British Columbia, Canada, Dec 8--14, 2019.<br>
                [ <a href="paper/xu_neurips19.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                X. Xia, T. Liu, N. Wang, B. Han, C. Gong, G. Niu, and M. Sugiyama.<br>
                Are anchor points really indispensable in label-noise learning?<br>
                In <i><a href="http://neurips.cc/Conferences/2019/" target="_blank">Advances in Neural Information Processing Systems 32 (NeurIPS 2019)</a></i>,
                pp. 6838--6849, Vancouver, British Columbia, Canada, Dec 8--14, 2019.<br>
                [ <a href="paper/xia_neurips19.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                Y.-G. Hsieh, G. Niu, and M. Sugiyama.<br>
                Classification from positive, unlabeled and biased negative data.<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2019" target="_blank">36th International Conference on Machine Learning (ICML 2019)</a></i>,
                PMLR, vol. 97, pp. 2820--2829, Long Beach, California, USA, Jun 9--15, 2019.<br>
                [ <a href="paper/hsieh_icml19.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                T. Ishida, G. Niu, A. K. Menon, and M. Sugiyama.<br>
                Complementary-label learning for arbitrary losses and models.<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2019" target="_blank">36th International Conference on Machine Learning (ICML 2019)</a></i>,
                PMLR, vol. 97, pp. 2971--2980, Long Beach, California, USA, Jun 9--15, 2019.<br>
                [ <a href="paper/ishida_icml19.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                X. Yu, B. Han, J. Yao, G. Niu, I. W. Tsang, and M. Sugiyama.<br>
                How does disagreement help generalization against label corruption?<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2019" target="_blank">36th International Conference on Machine Learning (ICML 2019)</a></i>,
                PMLR, vol. 97, pp. 7164--7173, Long Beach, California, USA, Jun 9--15, 2019.<br>
                [ <a href="paper/yu_icml19.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                N. Lu, G. Niu, A. K. Menon, and M. Sugiyama.<br>
                On the minimal supervision for training any binary classifier from only unlabeled data.<br>
                In <i>Proceedings of <a href="http://iclr.cc/Conferences/2019/" target="_blank">7th International Conference on Learning Representations (ICLR 2019)</a></i>,
                18 pages, New Orleans, Louisiana, USA, May 6--9, 2019.<br>
                [ <a href="paper/lu_iclr19.pdf" target="_blank">paper</a>,
                <a href="http://openreview.net/forum?id=B1xWcj0qYm" target="_blank">OpenReview</a> ]
            </p></li>
            <li><p>
                T. Ishida, G. Niu, and M. Sugiyama.<br>
                Binary classification from positive-confidence data.<br>
                In <i><a href="http://neurips.cc/Conferences/2018/" target="_blank">Advances in Neural Information Processing Systems 31 (NeurIPS 2018)</a></i>,
                pp. 5917--5928, Montreal, Quebec, Canada, Dec 2--8, 2018.<br>
                <font color="#008800">(This paper was selected for spotlight presentation;
                spotlights : acceptance : submissions = 168 : 1011 : 4856)</font><br>
                [ <a href="paper/ishida_neurips18.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                B. Han*, J. Yao*, G. Niu, M. Zhou, I. W. Tsang, Y. Zhang, and M. Sugiyama.<br>
                Masking: A new perspective of noisy supervision.<br>
                In <i><a href="http://neurips.cc/Conferences/2018/" target="_blank">Advances in Neural Information Processing Systems 31 (NeurIPS 2018)</a></i>,
                pp. 5836--5846, Montreal, Quebec, Canada, Dec 2--8, 2018.<br>
                [ <a href="paper/han_neurips18a.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                B. Han*, Q. Yao*, X. Yu, G. Niu, M. Xu, W. Hu, I. W. Tsang, and M. Sugiyama.<br>
                Co-teaching: Robust training of deep neural networks with extremely noisy labels.<br>
                In <i><a href="http://neurips.cc/Conferences/2018/" target="_blank">Advances in Neural Information Processing Systems 31 (NeurIPS 2018)</a></i>,
                pp. 8527--8537, Montreal, Quebec, Canada, Dec 2--8, 2018.<br>
                [ <a href="paper/han_neurips18b.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                S.-J. Huang, M. Xu, M.-K. Xie, M. Sugiyama, G. Niu, and S. Chen.<br>
                Active feature acquisition with supervised matrix completion.<br>
                In <i>Proceedings of <a href="http://www.kdd.org/kdd2018/" target="_blank">24th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD 2018)</a></i>,
                pp. 1571--1579, London, UK, Aug 19--23, 2018.<br>
                [ <a href="paper/huang_kdd18.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                W. Hu, G. Niu, I. Sato, and M. Sugiyama.<br>
                Does distributionally robust supervised learning give robust classifiers?<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2018" target="_blank">35th International Conference on Machine Learning (ICML 2018)</a></i>,
                PMLR, vol. 80, pp. 2029--2037, Stockholm, Sweden, Jul 10--15, 2018.<br>
                [ <a href="paper/hu_icml18.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                H. Bao, G. Niu, and M. Sugiyama.<br>
                Classification from pairwise similarity and unlabeled data.<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2018" target="_blank">35th International Conference on Machine Learning (ICML 2018)</a></i>,
                PMLR, vol. 80, pp. 452--461, Stockholm, Sweden, Jul 10--15, 2018.<br>
                [ <a href="paper/bao_icml18.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                R. Kiryo, G. Niu, M. C. du Plessis, and M. Sugiyama.<br>
                Positive-unlabeled learning with non-negative risk estimator.<br>
                In <i><a href="http://neurips.cc/Conferences/2017/" target="_blank">Advances in Neural Information Processing Systems 30 (NeurIPS 2017)</a></i>,
                pp. 1674--1684, Long Beach, California, USA, Dec 4--9, 2017.<br>
                <font color="#008800">(This paper was selected for oral presentation;
                orals : acceptance : submissions = 40 : 678 : 3240)</font><br>
                [ <a href="paper/kiryo_nips17.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                T. Ishida, G. Niu, W. Hu, and M. Sugiyama.<br>
                Learning from complementary labels.<br>
                In <i><a href="http://neurips.cc/Conferences/2017/" target="_blank">Advances in Neural Information Processing Systems 30 (NeurIPS 2017)</a></i>,
                pp. 5644--5654, Long Beach, California, USA, Dec 4--9, 2017.<br>
                [ <a href="paper/ishida_nips17.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                H. Shiino, H. Sasaki, G. Niu, and M. Sugiyama.<br>
                Whitening-free least-squares non-Gaussian component analysis.<br>
                In <i>Proceedings of <a href="http://acml-conf.org/2017/" target="_blank">9th Asian Conference on Machine Learning (ACML 2017)</a></i>,
                PMLR, vol. 77, pp. 375--390, Seoul, Korea, Nov 15--17, 2017.<br>
                <font color="#008800">(This paper received Best Paper Runner-up Award)</font><br>
                [ <a href="paper/shiino_acml17.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                T. Sakai, M. C. du Plessis, G. Niu, and M. Sugiyama.<br>
                Semi-supervised classification based on classification from positive and unlabeled data.<br>
                In <i>Proceedings of <a href="http://icml.cc/Conferences/2017" target="_blank">34th International Conference on Machine Learning (ICML 2017)</a></i>,
                PMLR, vol. 70, pp. 2998--3006, Sydney, Australia, Aug 6--11, 2017.<br>
                [ <a href="paper/sakai_icml17.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                G. Niu, M. C. du Plessis, T. Sakai, Y. Ma, and M. Sugiyama.<br>
                Theoretical comparisons of positive-unlabeled learning against positive-negative learning.<br>
                In <i><a href="http://neurips.cc/Conferences/2016/" target="_blank">Advances in Neural Information Processing Systems 29 (NeurIPS 2016)</a></i>,
                pp. 1199--1207, Barcelona, Spain, Dec 5--10, 2016.<br>
                [ <a href="paper/niu_nips16.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                H. Sasaki, G. Niu, and M. Sugiyama.<br>
                Non-Gaussian component analysis with log-density gradient estimation.<br>
                In <i>Proceedings of <a href="http://aistats.org/aistats2016/" target="_blank">19th International Conference on Artificial Intelligence and Statistics (AISTATS 2016)</a></i>,
                PMLR, vol. 51, pp. 1177--1185, Cadiz, Spain, May 9--11, 2016.<br>
                [ <a href="paper/sasaki_aistats16.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                T. Zhao, G. Niu, N. Xie, J. Yang, and M. Sugiyama.<br>
                Regularized policy gradients: Direct variance reduction in policy gradient estimation.<br>
                In <i>Proceedings of <a href="http://acml-conf.org/2015/" target="_blank">7th Asian Conference on Machine Learning (ACML 2015)</a></i>,
                PMLR, vol. 45, pp. 333--348, Hong Kong, China, Nov 20--22, 2015.<br>
                [ <a href="paper/zhao_acml15.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                M. C. du Plessis, G. Niu, and M. Sugiyama.<br>
                Class-prior estimation for learning from positive and unlabeled data.<br>
                In <i>Proceedings of <a href="http://acml-conf.org/2015/" target="_blank">7th Asian Conference on Machine Learning (ACML 2015)</a></i>,
                PMLR, vol. 45, pp. 221--236, Hong Kong, China, Nov 20--22, 2015.<br>
                [ <a href="paper/duplessis_acml15.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                M. C. du Plessis, G. Niu, and M. Sugiyama.<br>
                Convex formulation for learning from positive and unlabeled data.<br>
                In <i>Proceedings of <a href="http://icml.cc/2015/" target="_blank">32nd International Conference on Machine Learning (ICML 2015)</a></i>,
                PMLR, vol. 37, pp. 1386--1394, Lille, France, Jul 6--11, 2015.<br>
                [ <a href="paper/duplessis_icml15.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                M. C. du Plessis, G. Niu, and M. Sugiyama.<br>
                Analysis of learning from positive and unlabeled data.<br>
                In <i><a href="http://neurips.cc/Conferences/2014/" target="_blank">Advances in Neural Information Processing Systems 27 (NeurIPS 2014)</a></i>,
                pp. 703--711, Montreal, Quebec, Canada, Dec 8--13, 2014.<br>
                [ <a href="paper/duplessis_nips14.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                G. Niu, B. Dai, M. C. du Plessis, and M. Sugiyama.<br>
                Transductive learning with multi-class volume approximation.<br>
                In <i>Proceedings of <a href="http://icml.cc/2014/" target="_blank">31st International Conference on Machine Learning (ICML 2014)</a></i>,
                PMLR, vol. 32, no. 2, pp. 1377--1385, Beijing, China, Jun 21--26, 2014.<br>
                [ <a href="paper/niu_icml14.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                M. C. du Plessis, G. Niu, and M. Sugiyama.<br>
                Clustering unclustered data: Unsupervised binary labeling of two datasets having different class balances.<br>
                In <i>Proceedings of the 2013 Conference on Technologies and Applications of Artificial Intelligence (TAAI 2013)</i>,
                pp. 1--6, Taipei, Taiwan, Dec 6--8, 2013.<br>
                <font color="#008800">(This paper received Best Paper Award)</font><br>
                [ <a href="paper/duplessis_taai13.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                G. Niu, W. Jitkrittum, B. Dai, H. Hachiya, and M. Sugiyama.<br>
                Squared-loss mutual information regularization: A novel information-theoretic approach to semi-supervised learning.<br>
                In <i>Proceedings of <a href="http://icml.cc/2013/" target="_blank">30th International Conference on Machine Learning (ICML 2013)</a></i>,
                PMLR, vol. 28, no. 3, pp. 10--18, Atlanta, Georgia, USA, Jun 16--21, 2013.<br>
                [ <a href="paper/niu_icml13.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                G. Niu, B. Dai, M. Yamada, and M. Sugiyama.<br>
                Information-theoretic semi-supervised metric learning via entropy regularization.<br>
                In <i>Proceedings of <a href="http://icml.cc/2012/" target="_blank">29th International Conference on Machine Learning (ICML 2012)</a></i>,
                pp. 89--96, Edinburgh, Scotland, Jun 26--Jul 1, 2012.<br>
                [ <a href="paper/niu_icml12.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                T. Zhao, H. Hachiya, G. Niu, and M. Sugiyama.<br>
                Analysis and improvement of policy gradient estimation.<br>
                In <i><a href="http://neurips.cc/Conferences/2011/" target="_blank">Advances in Neural Information Processing Systems 24 (NeurIPS 2011)</a></i>,
                pp. 262--270, Granada, Spain, Dec 12--17, 2011.<br>
                [ <a href="paper/zhao_nips11.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                M. Yamada, G. Niu, J. Takagi, and M. Sugiyama.<br>
                Computationally efficient sufficient dimension reduction via squared-loss mutual information.<br>
                In <i>Proceedings of 3rd Asian Conference on Machine Learning (ACML 2011)</i>,
                PMLR, vol. 20, pp. 247--262, Taoyuan, Taiwan, Nov 13--15, 2011.<br>
                [ <a href="paper/yamada_acml11.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                G. Niu, B. Dai, L. Shang, and M. Sugiyama.<br>
                Maximum volume clustering.<br>
                In <i>Proceedings of <a href="http://aistats.org/aistats2011/" target="_blank">14th International Conference on Artificial Intelligence and Statistics (AISTATS 2011)</a></i>,
                PMLR, vol. 15, pp. 561--569, Fort Lauderdale, Florida, USA, Apr 11--13, 2011.<br>
                [ <a href="paper/niu_aistats11.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                B. Dai, B. Hu, and G. Niu.<br>
                Bayesian maximum margin clustering.<br>
                In <i>Proceedings of 10th IEEE International Conference on Data Mining (ICDM 2010)</i>,
                pp. 108--117, Sydney, Australia, Dec 14--17, 2010.<br>
                [ <a href="paper/dai_icdm10.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                G. Niu, B. Dai, Y. Ji, and L. Shang.<br>
                Rough margin based core vector machine.<br>
                In <i>Proceedings of 14th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2010)</i>,
                LNCS, vol. 6118, pp. 134--141, Hyderabad, India, Jun 21--24, 2010.<br>
                [ <a href="paper/niu_pakdd10.pdf" target="_blank">paper</a> ]
            </p></li>
            <li><p>
                B. Dai and G. Niu.<br>
                Compact margin machine.<br>
                In <i>Proceedings of 14th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2010)</i>,
                LNCS, vol. 6119, pp. 507--514, Hyderabad, India, Jun 21--24, 2010.<br>
                [ <a href="paper/dai_pakdd10.pdf" target="_blank">paper</a> ]
            </p></li>
        </ol>
    </div>

    <div>
        <h2><hr><a name="journal"></a>Journal Articles</h2>
        <ol>
            <li><p>
                Y. Gao, D. Wu, J. Zhang, G. Gan, X.-T. Xia, G. Niu, and M. Sugiyama.<br>
                On the effectiveness of adversarial training against backdoor attacks.<br>
                <i><a href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385" target="_blank">IEEE Transactions on Neural Networks and Learning Systems</a></i>, to appear.<br>
                [ <a href="http://doi.org/10.1109/TNNLS.2023.3281872" target="_blank">link</a> ]
            </p></li>
            <li><p>
                J. Lv, B. Liu, L. Feng, N. Xu, M. Xu, B. An, G. Niu, X. Geng, and M. Sugiyama.<br>
                On the robustness of average losses for partial-label learning.<br>
                <i><a href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34" target="_blank">IEEE Transactions on Pattern Analysis and Machine Intelligence</a></i>, vol. 46, no. 5, pp. 2569--2583, 2024.<br>
                [ <a href="http://doi.org/10.1109/TPAMI.2023.3275249" target="_blank">link</a> ]
            </p></li>
            <li><p>
                H. Wang, R. Xiao, Y. Li, L. Feng, G. Niu, G. Chen, and J. Zhao.<br>
                PiCO+: Contrastive label disambiguation for robust partial label learning.<br>
                <i><a href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34" target="_blank">IEEE Transactions on Pattern Analysis and Machine Intelligence</a></i>, vol. 46, no. 5, pp. 3183--3198, 2024.<br>
                [ <a href="http://doi.org/10.1109/TPAMI.2023.3342650" target="_blank">link</a> ]
            </p></li>
            <li><p>
                S. Chen, C. Gong, X. Li, J. Yang, G. Niu, and M. Sugiyama.<br>
                Boundary-restricted metric learning.<br>
                <i><a href="http://www.springer.com/journal/10994" target="_blank">Machine Learning</a></i>, vol. 112, no. 12, pp. 4723--4762, 2023.<br>
                [ <a href="http://doi.org/10.1007/s10994-023-06380-3" target="_blank">link</a> ]
            </p></li>
            <li><p>
                S. Yang, S. Wu, E. Yang, B. Han, Y. Liu, M. Xu, G. Niu, and T. Liu.<br>
                A parametrical model for instance-dependent label noise.<br>
                <i><a href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34" target="_blank">IEEE Transactions on Pattern Analysis and Machine Intelligence</a></i>, vol. 45, no. 12, pp. 14055--14068, 2023.<br>
                [ <a href="http://doi.org/10.1109/TPAMI.2023.3301876" target="_blank">link</a> ]
            </p></li>
            <li><p>
                L. Feng, S. Shu, Y. Cao, L. Tao, H. Wei, T. Xiang, B. An, and G. Niu.<br>
                Multiple-instance learning from unlabeled bags with pairwise similarity.<br>
                <i><a href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=69" target="_blank">IEEE Transactions on Knowledge and Data Engineering</a></i>, vol. 35, no. 11, pp. 11599--11609, 2023.<br>
                [ <a href="http://doi.org/10.1109/TKDE.2022.3232141" target="_blank">link</a> ]
            </p></li>
            <li><p>
                T. Zhao, S. Wu, G. Li, Y. Chen, G. Niu, and M. Sugiyama.<br>
                Learning intention-aware policies in deep reinforcement learning.<br>
                <i><a href="http://direct.mit.edu/neco" target="_blank">Neural Computation</a></i>, vol. 35, no. 10, pp. 1657--1677, 2023.<br>
                [ <a href="http://doi.org/10.1162/neco_a_01607" target="_blank">link</a> ]
            </p></li>
            <li><p>
                C. Gong, Y. Ding, B. Han, G. Niu, J. Yang, J. You, D. Tao, and M. Sugiyama.<br>
                Class-wise denoising for robust learning under label noise.<br>
                <i><a href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34" target="_blank">IEEE Transactions on Pattern Analysis and Machine Intelligence</a></i>, vol. 45, no. 3, pp. 2835--2848, 2023.<br>
                [ <a href="http://doi.org/10.1109/TPAMI.2022.3178690" target="_blank">link</a> ]
            </p></li>
            <li><p>
                T. Zhao, Y. Wang, W. Sun, Y. Chen, G. Niu, and M. Sugiyama.<br>
                Representation learning for continuous action spaces is beneficial for efficient policy learning.<br>
                <i><a href="http://www.journals.elsevier.com/neural-networks" target="_blank">Neural Networks</a></i>, vol. 159, pp. 137--152, 2023.<br>
                [ <a href="http://doi.org/10.1016/j.neunet.2022.12.009" target="_blank">link</a> ]
            </p></li>
            <li><p>
                S. Wu, T. Liu, B. Han, J. Yu, G. Niu, and M. Sugiyama.<br>
                Learning from noisy pairwise similarity and unlabeled data.<br>
                <i><a href="http://jmlr.org/" target="_blank">Journal of Machine Learning Research</a></i>, vol. 23, no. 307, pp. 1--34, 2022.<br>
                [ <a href="http://www.jmlr.org/papers/v23/21-0946.html" target="_blank">link</a> ]
            </p></li>
            <li><p>
                Z. Wang, J. Jiang, B. Han, L. Feng, B. An, G. Niu, and G. Long.<br>
                SemiNLL: A framework of noisy-label learning by semi-supervised learning.<br>
                <i><a href="http://jmlr.org/tmlr/" target="_blank">Transactions on Machine Learning Research</a></i>, 07/2022, 25 pages, 2022.<br>
                [ <a href="http://openreview.net/forum?id=qzM1Tw5i7N" target="_blank">link</a> ]
            </p></li>
            <li><p>
                J. Zhang*, X. Xu*, B. Han, T. Liu, L. Cui, G. Niu, and M. Sugiyama.<br>
                NoiLIn: Improving adversarial training and correcting stereotype of noisy labels.<br>
                <i><a href="http://jmlr.org/tmlr/" target="_blank">Transactions on Machine Learning Research</a></i>, 06/2022, 25 pages, 2022.<br>
                [ <a href="http://openreview.net/forum?id=zlQXV7xtZs" target="_blank">link</a> ]
            </p></li>
            <li><p>
                Y. Pan, I. W. Tsang, W. Chen, G. Niu, and M. Sugiyama.<br>
                Fast and robust rank aggregation against model misspecification.<br>
                <i><a href="http://jmlr.org/" target="_blank">Journal of Machine Learning Research</a></i>, vol. 23, no. 23, pp. 1--35, 2022.<br>
                [ <a href="http://www.jmlr.org/papers/v23/20-315.html" target="_blank">link</a> ]
            </p></li>
            <li><p>
                W. Xu, G. Niu, A. Hyvärinen, and M. Sugiyama.<br>
                Direction matters: On influence-preserving graph summarization and max-cut principle for directed graphs.<br>
                <i><a href="http://direct.mit.edu/neco" target="_blank">Neural Computation</a></i>, vol. 33, no. 8, pp. 2128--2162, 2021.<br>
                [ <a href="http://doi.org/10.1162/neco_a_01402" target="_blank">link</a> ]
            </p></li>
            <li><p>
                T. Sakai, G. Niu, and M. Sugiyama.<br>
                Information-theoretic representation learning for positive-unlabeled classification.<br>
                <i><a href="http://direct.mit.edu/neco" target="_blank">Neural Computation</a></i>, vol. 33, no. 1, pp. 244--268, 2021.<br>
                [ <a href="http://doi.org/10.1162/neco_a_01337" target="_blank">link</a> ]
            </p></li>
            <li><p>
                H. Sasaki, T. Kanamori, A. Hyvärinen, G. Niu, and M. Sugiyama.<br>
                Mode-seeking clustering and density ridge estimation via direct estimation of density-derivative-ratios.<br>
                <i><a href="http://jmlr.org/" target="_blank">Journal of Machine Learning Research</a></i>, vol. 18, no. 180, pp. 1--45, 2018.<br>
                [ <a href="http://jmlr.org/papers/v18/17-380.html" target="_blank">link</a> ]
            </p></li>
            <li><p>
                T. Sakai, G. Niu, and M. Sugiyama.<br>
                Semi-supervised AUC optimization based on positive-unlabeled learning.<br>
                <i><a href="http://www.springer.com/journal/10994" target="_blank">Machine Learning</a></i>, vol. 107, no. 4, pp. 767--794, 2018.<br>
                [ <a href="http://doi.org/10.1007/s10994-017-5678-9" target="_blank">link</a> ]
            </p></li>
            <li><p>
                H. Sasaki, V. Tangkaratt, G. Niu, and M. Sugiyama.<br>
                Sufficient dimension reduction via direct estimation of the gradients of logarithmic conditional densities.<br>
                <i><a href="http://direct.mit.edu/neco" target="_blank">Neural Computation</a></i>, vol. 30, no. 2, pp. 477--504, 2018.<br>
                [ <a href="http://doi.org/10.1162/neco_a_01035" target="_blank">link</a> ]
            </p></li>
            <li><p>
                M. C. du Plessis*, G. Niu*, and M. Sugiyama.<br>
                Class-prior estimation for learning from positive and unlabeled data.<br>
                <i><a href="http://www.springer.com/journal/10994" target="_blank">Machine Learning</a></i>, vol. 106, no. 4, pp. 463--492, 2017.<br>
                [ <a href="http://doi.org/10.1007/s10994-016-5604-6" target="_blank">link</a> ]
            </p></li>
            <li><p>
                H. Sasaki, Y.-K. Noh, G. Niu, and M. Sugiyama.<br>
                Direct density-derivative estimation.<br>
                <i><a href="http://direct.mit.edu/neco" target="_blank">Neural Computation</a></i>,  vol. 28, no. 6, pp. 1101--1140, 2016.<br>
                [ <a href="http://doi.org/10.1162/neco_a_00835" target="_blank">link</a> ]
            </p></li>
            <li><p>
                G. Niu, B. Dai, M. Yamada, and M. Sugiyama.<br>
                Information-theoretic semi-supervised metric learning via entropy regularization.<br>
                <i><a href="http://direct.mit.edu/neco" target="_blank">Neural Computation</a></i>,  vol. 26, no. 8, pp. 1717--1762, 2014.<br>
                [ <a href="http://doi.org/10.1162/neco_a_00614" target="_blank">link</a> ]
            </p></li>
            <li><p>
                D. Calandriello, G. Niu, and M. Sugiyama.<br>
                Semi-supervised information-maximization clustering.<br>
                <i><a href="http://www.journals.elsevier.com/neural-networks" target="_blank">Neural Networks</a></i>, vol. 57, pp. 103--111, 2014.<br>
                [ <a href="http://doi.org/10.1016/j.neunet.2014.05.016" target="_blank">link</a> ]
            </p></li>
            <li><p>
                M. Sugiyama, G. Niu, M. Yamada, M. Kimura, and H. Hachiya.<br>
                Information-maximization clustering based on squared-loss mutual information.<br>
                <i><a href="http://direct.mit.edu/neco" target="_blank">Neural Computation</a></i>, vol. 26, no. 1, pp. 84--131, 2014.<br>
                [ <a href="http://doi.org/10.1162/neco_a_00534" target="_blank">link</a> ]
            </p></li>
            <li><p>
                G. Niu, B. Dai, L. Shang, and M. Sugiyama.<br>
                Maximum volume clustering: A new discriminative clustering approach.<br>
                <i><a href="http://jmlr.org/" target="_blank">Journal of Machine Learning Research</a></i>, vol. 14 (Sep), pp. 2641--2687, 2013.<br>
                [ <a href="http://jmlr.org/papers/v14/niu13a.html" target="_blank">link</a> ]
            </p></li>
            <li><p>
                T. Zhao, H. Hachiya, G. Niu, and M. Sugiyama.<br>
                Analysis and improvement of policy gradient estimation.<br>
                <i><a href="http://www.journals.elsevier.com/neural-networks" target="_blank">Neural Networks</a></i>, vol. 26, pp. 118--129, 2012.<br>
                [ <a href="http://doi.org/10.1016/j.neunet.2011.09.005" target="_blank">link</a> ]
            </p></li>
            <li><p>
                Y. Ji, J. Chen, G. Niu, L. Shang, and X. Dai.<br>
                Transfer learning via multi-view principal component analysis.<br>
                <i><a href="http://www.springer.com/journal/11390" target="_blank">Journal of Computer Science and Technology</a></i>, vol. 26, no. 1, pp. 81--98, 2011.<br>
                [ <a href="http://doi.org/10.1007/s11390-011-9417-6" target="_blank">link</a> ]
            </p></li>
        </ol>
    </div>

    <div>
        <h2><hr><a name="thesis"></a>Theses</h2>
        <ol>
            <li><p>
                Gang Niu.<br>
                <i>Discriminative methods with imperfect supervision in machine learning</i> (204 pages).<br>
                Doctoral Thesis, Department of Computer Science, Tokyo Institute of Technology, Sep 2013.
            </p></li>
            <li><p>
                Gang Niu.<br>
                <i>Support vector learning based on rough set modeling</i> (71 pages in Chinese).<br>
                Master Thesis, Department of Computer Science and Technology, Nanjing University, May 2010.
            </p></li>
        </ol>
    </div>

</td>
</tr>
</table>
</body>
</html>
